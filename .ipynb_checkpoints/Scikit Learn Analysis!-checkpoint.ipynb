{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import precision_score\n",
    "    \n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in the data\n",
    "data = pd.read_csv('AggredgatedData.csv', sep=',', na_values=[\" \", \"\"], index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##I. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False  True False  True False False False  True  True False\n",
      " False False  True False False  True False False  True  True False  True\n",
      " False False  True  True  True False False False  True False False False\n",
      "  True False  True False False False False False  True False False False\n",
      " False False  True False False]\n"
     ]
    }
   ],
   "source": [
    "features = list(data.columns[1:-1])\n",
    "X = data[features]\n",
    "Y = data['2016ODabovenatavg']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, Y_train) \n",
    "#kernel? C?\n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "\n",
    "print(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scoring='f1_macro'\n",
    "scores = cross_val_score(clf, X, Y, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70588235  0.6875      0.5         0.6875      0.875       0.625       0.8125\n",
      "  0.6875      0.6         0.66666667]\n",
      "Accuracy: 0.68 (+/- 0.20)\n"
     ]
    }
   ],
   "source": [
    "print scores\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##II. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True False  True  True False False  True  True False\n",
      " False False False False  True  True False False  True  True False False\n",
      " False False  True  True  True False False False  True False False False\n",
      "  True False  True False False False False  True  True False  True  True\n",
      " False False  True False False]\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression()\n",
    "clf1.fit(X_train, Y_train) \n",
    "#kernel? C?\n",
    "LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, \n",
    "                   intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', \n",
    "                   max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "\n",
    "print(clf1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70588235  0.625       0.375       0.6875      0.875       0.625       0.8125\n",
      "  0.6875      0.66666667  0.66666667]\n",
      "Accuracy: 0.67 (+/- 0.25)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf1, X, Y, cv = 10)\n",
    "print scores\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=100.00\n",
      "Sparsity with L1 penalty: 7.14%\n",
      "score with L1 penalty: 0.8113\n",
      "Sparsity with L2 penalty: 0.00%\n",
      "score with L2 penalty: 0.8302\n",
      "C=1.00\n",
      "Sparsity with L1 penalty: 50.00%\n",
      "score with L1 penalty: 0.7610\n",
      "Sparsity with L2 penalty: 0.00%\n",
      "score with L2 penalty: 0.7862\n",
      "C=0.01\n",
      "Sparsity with L1 penalty: 96.43%\n",
      "score with L1 penalty: 0.6038\n",
      "Sparsity with L2 penalty: 0.00%\n",
      "score with L2 penalty: 0.7170\n"
     ]
    }
   ],
   "source": [
    "#Comparison of the sparsity (% of zero coefficients) of solutions when L1 and L2 penalty \n",
    "#are used for different values of C. \n",
    "#We can see that large values of C give more freedom to the model. \n",
    "#Conversely, smaller values of C constrain the model more. \n",
    "#In the L1 penalty case, this leads to sparser solutions.\n",
    "\n",
    "for i, C in enumerate((100, 1, 0.01)):\n",
    "    # turn down tolerance for short training time\n",
    "    clf_l1_LR = LogisticRegression(C=C, penalty='l1', tol=0.01)\n",
    "    clf_l2_LR = LogisticRegression(C=C, penalty='l2', tol=0.01)\n",
    "    clf_l1_LR.fit(X, Y)\n",
    "    clf_l2_LR.fit(X, Y)\n",
    "\n",
    "    coef_l1_LR = clf_l1_LR.coef_.ravel()\n",
    "    coef_l2_LR = clf_l2_LR.coef_.ravel()\n",
    "\n",
    "    # coef_l1_LR contains zeros due to the\n",
    "    # L1 sparsity inducing norm\n",
    "\n",
    "    sparsity_l1_LR = np.mean(coef_l1_LR == 0) * 100\n",
    "    sparsity_l2_LR = np.mean(coef_l2_LR == 0) * 100\n",
    "\n",
    "    print(\"C=%.2f\" % C)\n",
    "    print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity_l1_LR)\n",
    "    print(\"score with L1 penalty: %.4f\" % clf_l1_LR.score(X, Y))\n",
    "    print(\"Sparsity with L2 penalty: %.2f%%\" % sparsity_l2_LR)\n",
    "    print(\"score with L2 penalty: %.4f\" % clf_l2_LR.score(X, Y))\n",
    "    \n",
    "    l1_plot = plt.subplot(3, 2, 2 * i + 1)\n",
    "    l2_plot = plt.subplot(3, 2, 2 * (i + 1))\n",
    "    if i == 0:\n",
    "        l1_plot.set_title(\"L1 penalty\")\n",
    "        l2_plot.set_title(\"L2 penalty\")\n",
    "\n",
    "    l1_plot.imshow(np.abs(coef_l1_LR.reshape(8, 8)), interpolation='nearest',\n",
    "                   cmap='binary', vmax=1, vmin=0)\n",
    "    l2_plot.imshow(np.abs(coef_l2_LR.reshape(8, 8)), interpolation='nearest',\n",
    "                   cmap='binary', vmax=1, vmin=0)\n",
    "    plt.text(-8, 3, \"C = %.2f\" % C)\n",
    "\n",
    "    l1_plot.set_xticks(())\n",
    "    l1_plot.set_yticks(())\n",
    "    l2_plot.set_xticks(())\n",
    "    l2_plot.set_yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##III. K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
