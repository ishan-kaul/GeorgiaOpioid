{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import precision_score\n",
    "    \n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in the data\n",
    "data = pd.read_csv('AggredgatedData.csv', sep=',', na_values=[\" \", \"\"], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = list(data.columns[1:-1])\n",
    "X = data[features]\n",
    "Y = data['2016ODabovenatavg']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##I. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros: \n",
    "* Effective in high dimensional spaces.\n",
    "* Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "* Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "* Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "Cons:\n",
    "\n",
    "* If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.\n",
    "* SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: linear | Degree: 1\n",
      "[ 0.64705882  0.75        0.6875      0.625       0.75        0.6875\n",
      "  0.8125      0.625       0.6         0.73333333]\n",
      "Accuracy: 0.69 (+/- 0.13)\n",
      "Kernel: linear | Degree: 3\n",
      "[ 0.64705882  0.75        0.6875      0.625       0.75        0.6875\n",
      "  0.8125      0.625       0.6         0.73333333]\n",
      "Accuracy: 0.69 (+/- 0.13)\n",
      "Kernel: linear | Degree: 5\n",
      "[ 0.64705882  0.75        0.6875      0.625       0.75        0.6875\n",
      "  0.8125      0.625       0.6         0.73333333]\n",
      "Accuracy: 0.69 (+/- 0.13)\n",
      "Kernel: linear | Degree: 7\n",
      "[ 0.64705882  0.75        0.6875      0.625       0.75        0.6875\n",
      "  0.8125      0.625       0.6         0.73333333]\n",
      "Accuracy: 0.69 (+/- 0.13)\n",
      "Kernel: polynomial | Degree: 1\n",
      "[ 0.64705882  0.75        0.6875      0.625       0.75        0.6875\n",
      "  0.8125      0.625       0.6         0.73333333]\n",
      "Accuracy: 0.69 (+/- 0.13)\n",
      "Kernel: polynomial | Degree: 3\n",
      "[ 0.64705882  0.75        0.6875      0.625       0.75        0.6875\n",
      "  0.8125      0.625       0.6         0.73333333]\n",
      "Accuracy: 0.69 (+/- 0.13)\n",
      "Kernel: polynomial | Degree: 5\n",
      "[ 0.64705882  0.75        0.6875      0.625       0.75        0.6875\n",
      "  0.8125      0.625       0.6         0.73333333]\n",
      "Accuracy: 0.69 (+/- 0.13)\n",
      "Kernel: polynomial | Degree: 7\n",
      "[ 0.64705882  0.75        0.6875      0.625       0.75        0.6875\n",
      "  0.8125      0.625       0.6         0.73333333]\n",
      "Accuracy: 0.69 (+/- 0.13)\n",
      "Kernel: rbf | Degree: 1\n",
      "[ 0.64705882  0.75        0.6875      0.625       0.75        0.6875\n",
      "  0.8125      0.625       0.6         0.73333333]\n",
      "Accuracy: 0.69 (+/- 0.13)\n",
      "Kernel: rbf | Degree: 3\n",
      "[ 0.64705882  0.75        0.6875      0.625       0.75        0.6875\n",
      "  0.8125      0.625       0.6         0.73333333]\n",
      "Accuracy: 0.69 (+/- 0.13)\n",
      "Kernel: rbf | Degree: 5\n",
      "[ 0.64705882  0.75        0.6875      0.625       0.75        0.6875\n",
      "  0.8125      0.625       0.6         0.73333333]\n",
      "Accuracy: 0.69 (+/- 0.13)\n",
      "Kernel: rbf | Degree: 7\n",
      "[ 0.64705882  0.75        0.6875      0.625       0.75        0.6875\n",
      "  0.8125      0.625       0.6         0.73333333]\n",
      "Accuracy: 0.69 (+/- 0.13)\n",
      "Kernel: sigmoid | Degree: 1\n",
      "[ 0.64705882  0.75        0.6875      0.625       0.75        0.6875\n",
      "  0.8125      0.625       0.6         0.73333333]\n",
      "Accuracy: 0.69 (+/- 0.13)\n",
      "Kernel: sigmoid | Degree: 3\n",
      "[ 0.64705882  0.75        0.6875      0.625       0.75        0.6875\n",
      "  0.8125      0.625       0.6         0.73333333]\n",
      "Accuracy: 0.69 (+/- 0.13)\n",
      "Kernel: sigmoid | Degree: 5\n",
      "[ 0.64705882  0.75        0.6875      0.625       0.75        0.6875\n",
      "  0.8125      0.625       0.6         0.73333333]\n",
      "Accuracy: 0.69 (+/- 0.13)\n",
      "Kernel: sigmoid | Degree: 7\n",
      "[ 0.64705882  0.75        0.6875      0.625       0.75        0.6875\n",
      "  0.8125      0.625       0.6         0.73333333]\n",
      "Accuracy: 0.69 (+/- 0.13)\n"
     ]
    }
   ],
   "source": [
    "kernels = ['linear', 'polynomial', 'rbf', 'sigmoid']\n",
    "\n",
    "for i in kernels:\n",
    "    for j in range(1, 9, 2):\n",
    "        clf = SVC()\n",
    "        clf.fit(X_train, Y_train) \n",
    "        #kernel? C?\n",
    "        SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "            decision_function_shape='ovr', degree=j, gamma='auto', kernel=i,\n",
    "            max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "            tol=0.001, verbose=False)\n",
    "        scores = cross_val_score(clf, X, Y, cv = 10)\n",
    "\n",
    "        print (\"Kernel: %s | Degree: %i\" % (i, j))\n",
    "        print scores\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##II. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the ‘multi_class’ option is set to ‘ovr’, and uses the cross- entropy loss if the ‘multi_class’ option is set to ‘multinomial’. (Currently the ‘multinomial’ option is supported only by the ‘lbfgs’, ‘sag’ and ‘newton-cg’ solvers.)\n",
    "This class implements regularized logistic regression using the ‘liblinear’ library, ‘newton-cg’, ‘sag’ and ‘lbfgs’ solvers. It can handle both dense and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit floats for optimal performance; any other input format will be converted (and copied).\n",
    "The ‘newton-cg’, ‘sag’, and ‘lbfgs’ solvers support only L2 regularization with primal formulation. The ‘liblinear’ solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True False  True  True False False  True  True False\n",
      " False False False False  True  True False False  True  True False False\n",
      " False False  True  True False False False False  True False False False\n",
      "  True False  True False False False False False  True False  True  True\n",
      " False False  True False False]\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression()\n",
    "clf1.fit(X_train, Y_train) \n",
    "#kernel? C?\n",
    "LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, \n",
    "                   intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', \n",
    "                   max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "\n",
    "print(clf1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70588235  0.75        0.375       0.6875      0.875       0.625       0.8125\n",
      "  0.6875      0.66666667  0.66666667]\n",
      "Accuracy: 0.69 (+/- 0.25)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf1, X, Y, cv = 10)\n",
    "print scores\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=100.00\n",
      "Sparsity with L1 penalty: 6.67%\n",
      "score with L1 penalty: 0.8616\n",
      "Sparsity with L2 penalty: 0.00%\n",
      "score with L2 penalty: 0.8616\n",
      "C=1.00\n",
      "Sparsity with L1 penalty: 50.00%\n",
      "score with L1 penalty: 0.7547\n",
      "Sparsity with L2 penalty: 0.00%\n",
      "score with L2 penalty: 0.7862\n",
      "C=0.01\n",
      "Sparsity with L1 penalty: 93.33%\n",
      "score with L1 penalty: 0.6352\n",
      "Sparsity with L2 penalty: 0.00%\n",
      "score with L2 penalty: 0.7044\n"
     ]
    }
   ],
   "source": [
    "#Comparison of the sparsity (% of zero coefficients) of solutions when L1 and L2 penalty \n",
    "#are used for different values of C. \n",
    "#We can see that large values of C give more freedom to the model. \n",
    "#Conversely, smaller values of C constrain the model more. \n",
    "#In the L1 penalty case, this leads to sparser solutions.\n",
    "\n",
    "for i, C in enumerate((100, 1, 0.01)):\n",
    "    # turn down tolerance for short training time\n",
    "    clf_l1_LR = LogisticRegression(C=C, penalty='l1', tol=0.01)\n",
    "    clf_l2_LR = LogisticRegression(C=C, penalty='l2', tol=0.01)\n",
    "    clf_l1_LR.fit(X, Y)\n",
    "    clf_l2_LR.fit(X, Y)\n",
    "\n",
    "    coef_l1_LR = clf_l1_LR.coef_.ravel()\n",
    "    coef_l2_LR = clf_l2_LR.coef_.ravel()\n",
    "\n",
    "    # coef_l1_LR contains zeros due to the\n",
    "    # L1 sparsity inducing norm\n",
    "\n",
    "    sparsity_l1_LR = np.mean(coef_l1_LR == 0) * 100\n",
    "    sparsity_l2_LR = np.mean(coef_l2_LR == 0) * 100\n",
    "\n",
    "    print(\"C=%.2f\" % C)\n",
    "    print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity_l1_LR)\n",
    "    print(\"score with L1 penalty: %.4f\" % clf_l1_LR.score(X, Y))\n",
    "    print(\"Sparsity with L2 penalty: %.2f%%\" % sparsity_l2_LR)\n",
    "    print(\"score with L2 penalty: %.4f\" % clf_l2_LR.score(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##III. K-Means (2 centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X_train)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.85714286e-01,   7.14285714e-01,   9.90476190e-01,\n",
       "          1.06666667e+00,   2.66666667e-01,   1.26666667e+00,\n",
       "          1.45568932e-01,   1.73476153e-01,   4.51789978e-01,\n",
       "         -9.63652793e-02,  -4.64647099e-01,   2.21660688e-01,\n",
       "         -7.06148276e-02,   2.77903902e-02,   3.98652509e-01,\n",
       "          2.35427698e-02,  -5.50511346e-03,   8.18997065e-02,\n",
       "         -2.02946285e-02,  -6.40498423e-02,  -1.85447160e-01,\n",
       "          6.23701023e-02,   8.74484442e-02,   9.35764354e-02,\n",
       "          1.01390090e-02,   1.15824059e-02,   8.62609524e-01,\n",
       "          1.19457645e-04],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "         -1.14942529e-02,  -3.48484848e-01,   4.82758621e-01,\n",
       "         -2.33333333e-01,  -3.23529412e-01,  -6.61764706e-01,\n",
       "          1.65009940e-01,   1.53543307e-01,   5.85000000e+02,\n",
       "          1.33924653e-03,  -1.38186319e-01,  -2.83229388e-01,\n",
       "          3.83666476e-01,   1.37205270e-01,  -2.91226343e-01,\n",
       "          9.98613037e-03,   8.19848975e-03,   5.86000000e-01,\n",
       "          1.25274037e-04]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##SCORING?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros:\n",
    "* Efficiency.\n",
    "* Ease of implementation (lots of opportunities for code tuning).\n",
    "\n",
    "Cons:\n",
    "* requires a number of hyperparameters such as the regularization parameter and the number of iterations.\n",
    "* sensitive to feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "\n",
    "clf3.fit(X_train, Y_train)\n",
    "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
    "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
    "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
    "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
    "       shuffle=True, tol=None, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.23217789e+01,  -3.27011118e+01,   7.19424460e+01,\n",
       "         -5.23217789e+01,   7.19424460e+01,   3.27011118e+01,\n",
       "          3.39323448e+02,   3.81390625e+02,   2.80224415e+02,\n",
       "          4.88173195e+00,   5.42808692e+00,  -1.96832908e+01,\n",
       "         -2.75646968e+01,  -2.38539525e+01,  -4.16709189e+01,\n",
       "          1.13993476e+02,  -3.43336912e+01,  -1.27895818e+01,\n",
       "         -4.99360807e-01,   3.83814338e+01,  -9.61870462e+00,\n",
       "          7.76579272e+00,   8.87467740e+00,   1.10557228e+01,\n",
       "         -1.30150425e+02,  -4.07913669e+01,  -3.47670904e-01,\n",
       "         -4.41077476e-01,   7.75474166e+01,   9.56902786e-02]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-38.75832505])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.intercept_   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.64705882  0.375       0.625       0.625       0.5         0.5         0.6875\n",
      "  0.375       0.33333333  0.73333333]\n",
      "Accuracy: 0.54 (+/- 0.27)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf3, X, Y, cv = 10)\n",
    "print scores\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
