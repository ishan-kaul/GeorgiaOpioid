{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import precision_score\n",
    "    \n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in the data\n",
    "data = pd.read_csv('AggredgatedData.csv', sep=',', na_values=[\" \", \"\"], index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##I. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False  True False  True False False False  True  True False\n",
      " False False  True False False  True False False  True  True False  True\n",
      " False False  True  True  True False False False  True False False False\n",
      "  True False  True False False False False False  True False False False\n",
      " False False  True False False]\n"
     ]
    }
   ],
   "source": [
    "features = list(data.columns[1:-1])\n",
    "X = data[features]\n",
    "Y = data['2016ODabovenatavg']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, Y_train) \n",
    "#kernel? C?\n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "\n",
    "print(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scoring='f1_macro'\n",
    "scores = cross_val_score(clf, X, Y, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70588235  0.6875      0.5         0.6875      0.875       0.625       0.8125\n",
      "  0.6875      0.6         0.66666667]\n",
      "Accuracy: 0.68 (+/- 0.20)\n"
     ]
    }
   ],
   "source": [
    "print scores\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##II. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the ‘multi_class’ option is set to ‘ovr’, and uses the cross- entropy loss if the ‘multi_class’ option is set to ‘multinomial’. (Currently the ‘multinomial’ option is supported only by the ‘lbfgs’, ‘sag’ and ‘newton-cg’ solvers.)\n",
    "This class implements regularized logistic regression using the ‘liblinear’ library, ‘newton-cg’, ‘sag’ and ‘lbfgs’ solvers. It can handle both dense and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit floats for optimal performance; any other input format will be converted (and copied).\n",
    "The ‘newton-cg’, ‘sag’, and ‘lbfgs’ solvers support only L2 regularization with primal formulation. The ‘liblinear’ solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True False  True  True False False  True  True False\n",
      " False False False False  True  True False False  True  True False False\n",
      " False False  True  True  True False False False  True False False False\n",
      "  True False  True False False False False  True  True False  True  True\n",
      " False False  True False False]\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression()\n",
    "clf1.fit(X_train, Y_train) \n",
    "#kernel? C?\n",
    "LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, \n",
    "                   intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', \n",
    "                   max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "\n",
    "print(clf1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70588235  0.625       0.375       0.6875      0.875       0.625       0.8125\n",
      "  0.6875      0.66666667  0.66666667]\n",
      "Accuracy: 0.67 (+/- 0.25)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf1, X, Y, cv = 10)\n",
    "print scores\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=100.00\n",
      "Sparsity with L1 penalty: 7.14%\n",
      "score with L1 penalty: 0.8239\n",
      "Sparsity with L2 penalty: 0.00%\n",
      "score with L2 penalty: 0.8302\n",
      "C=1.00\n",
      "Sparsity with L1 penalty: 50.00%\n",
      "score with L1 penalty: 0.7673\n",
      "Sparsity with L2 penalty: 0.00%\n",
      "score with L2 penalty: 0.7862\n",
      "C=0.01\n",
      "Sparsity with L1 penalty: 96.43%\n",
      "score with L1 penalty: 0.6038\n",
      "Sparsity with L2 penalty: 0.00%\n",
      "score with L2 penalty: 0.7170\n"
     ]
    }
   ],
   "source": [
    "#Comparison of the sparsity (% of zero coefficients) of solutions when L1 and L2 penalty \n",
    "#are used for different values of C. \n",
    "#We can see that large values of C give more freedom to the model. \n",
    "#Conversely, smaller values of C constrain the model more. \n",
    "#In the L1 penalty case, this leads to sparser solutions.\n",
    "\n",
    "for i, C in enumerate((100, 1, 0.01)):\n",
    "    # turn down tolerance for short training time\n",
    "    clf_l1_LR = LogisticRegression(C=C, penalty='l1', tol=0.01)\n",
    "    clf_l2_LR = LogisticRegression(C=C, penalty='l2', tol=0.01)\n",
    "    clf_l1_LR.fit(X, Y)\n",
    "    clf_l2_LR.fit(X, Y)\n",
    "\n",
    "    coef_l1_LR = clf_l1_LR.coef_.ravel()\n",
    "    coef_l2_LR = clf_l2_LR.coef_.ravel()\n",
    "\n",
    "    # coef_l1_LR contains zeros due to the\n",
    "    # L1 sparsity inducing norm\n",
    "\n",
    "    sparsity_l1_LR = np.mean(coef_l1_LR == 0) * 100\n",
    "    sparsity_l2_LR = np.mean(coef_l2_LR == 0) * 100\n",
    "\n",
    "    print(\"C=%.2f\" % C)\n",
    "    print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity_l1_LR)\n",
    "    print(\"score with L1 penalty: %.4f\" % clf_l1_LR.score(X, Y))\n",
    "    print(\"Sparsity with L2 penalty: %.2f%%\" % sparsity_l2_LR)\n",
    "    print(\"score with L2 penalty: %.4f\" % clf_l2_LR.score(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##III. K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.85714286e-01,   7.14285714e-01,   9.90476190e-01,\n",
       "          1.06666667e+00,   2.66666667e-01,   1.26666667e+00,\n",
       "          1.45568932e-01,   1.73476153e-01,   4.51789978e-01,\n",
       "         -9.63652793e-02,  -4.64647099e-01,   2.21660688e-01,\n",
       "         -7.06148276e-02,   2.77903902e-02,   3.98652509e-01,\n",
       "          2.35427698e-02,  -5.50511346e-03,   8.18997065e-02,\n",
       "         -2.02946285e-02,  -6.40498423e-02,  -1.85447160e-01,\n",
       "          6.23701023e-02,   8.74484442e-02,   9.35764354e-02,\n",
       "          1.01390090e-02,   1.15824059e-02,   8.62609524e-01,\n",
       "          1.19457645e-04],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "         -1.14942529e-02,  -3.48484848e-01,   4.82758621e-01,\n",
       "         -2.33333333e-01,  -3.23529412e-01,  -6.61764706e-01,\n",
       "          1.65009940e-01,   1.53543307e-01,   5.85000000e+02,\n",
       "          1.33924653e-03,  -1.38186319e-01,  -2.83229388e-01,\n",
       "          3.83666476e-01,   1.37205270e-01,  -2.91226343e-01,\n",
       "          9.98613037e-03,   8.19848975e-03,   5.86000000e-01,\n",
       "          1.25274037e-04]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X_train)\n",
    "kmeans.labels_\n",
    "kmeans.predict(X_test)\n",
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
